{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from package.model import *\n",
    "from package.function import *\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltype = 'UNetPlusPlus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_args = dict(rotation_range=0.2,\n",
    "                     width_shift_range=0.05,\n",
    "                     height_shift_range=0.05,\n",
    "                     shear_range=0.05,\n",
    "                     zoom_range=0.05,\n",
    "                     horizontal_flip=True,\n",
    "                     fill_mode='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 47 images belonging to 1 classes.\n",
      "Found 47 images belonging to 1 classes.\n",
      "64/64 [==============================] - 14s 180ms/step - loss: 0.0268 - accuracy_within_05cm: 1.0000 - accuracy_within_1cm: 1.0000 - mean_error_cm: 1.5238e-04 - mean_io_u_1: 0.4959\n",
      "Validation loss: [0.02679346688091755, 1.0, 1.0, 0.00015238103515002877, 0.49593913555145264]\n",
      "Found 47 images belonging to 1 classes.\n",
      "Found 47 images belonging to 1 classes.\n",
      "64/64 [==============================] - 12s 173ms/step - loss: 0.0328 - accuracy_within_05cm: 1.0000 - accuracy_within_1cm: 1.0000 - mean_error_cm: 1.3608e-04 - mean_io_u_2: 0.4963\n",
      "Validation loss: [0.03281811997294426, 1.0, 1.0, 0.0001360830938210711, 0.4962839186191559]\n",
      "Found 47 images belonging to 1 classes.\n",
      "Found 47 images belonging to 1 classes.\n",
      "64/64 [==============================] - 12s 176ms/step - loss: 0.0373 - accuracy_within_05cm: 1.0000 - accuracy_within_1cm: 1.0000 - mean_error_cm: 1.6716e-04 - mean_io_u_3: 0.4959\n",
      "Validation loss: [0.03726731985807419, 1.0, 1.0, 0.00016716195386834443, 0.49587011337280273]\n",
      "Found 48 images belonging to 1 classes.\n",
      "Found 48 images belonging to 1 classes.\n",
      "64/64 [==============================] - 12s 179ms/step - loss: 0.0281 - accuracy_within_05cm: 1.0000 - accuracy_within_1cm: 1.0000 - mean_error_cm: 1.0335e-04 - mean_io_u_4: 0.4960\n",
      "Validation loss: [0.028085382655262947, 1.0, 1.0, 0.00010335038678022102, 0.4959716796875]\n",
      "Found 48 images belonging to 1 classes.\n",
      "Found 48 images belonging to 1 classes.\n",
      "64/64 [==============================] - 11s 168ms/step - loss: 0.0229 - accuracy_within_05cm: 1.0000 - accuracy_within_1cm: 1.0000 - mean_error_cm: 1.0655e-04 - mean_io_u_5: 0.4962\n",
      "Validation loss: [0.022853344678878784, 1.0, 1.0, 0.0001065461547113955, 0.4962286055088043]\n"
     ]
    }
   ],
   "source": [
    "# 評估驗證集\n",
    "for fold in range(1,6):\n",
    "    # Validation data generator\n",
    "    valGene = trainGenerator(batch_size=5,\n",
    "                            train_path=f'ETT_v3/Fold{fold}',\n",
    "                            image_folder='val',\n",
    "                            mask_folder='valannot',\n",
    "                            aug_dict=data_gen_args,\n",
    "                            save_to_dir=None)\n",
    "    model = UNetPlusPlus()\n",
    "    model.load_weights(f\"best_model/{modeltype}/Fold{fold}.keras\")\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[accuracy_within_05cm, accuracy_within_1cm,mean_error_cm,MeanIoU(num_classes=2)])\n",
    "    loss = model.evaluate(valGene, steps=64)\n",
    "    print('Validation loss:', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 9s 168ms/step - loss: 0.0229 - accuracy_within_05cm: 1.0000 - accuracy_within_1cm: 1.0000 - mean_error_cm: 1.3754e-04 - mean_io_u_6: 0.4963\n",
      "Validation loss: [0.022881707176566124, 1.0, 1.0, 0.00013754017709288746, 0.496279239654541]\n",
      "47/47 [==============================] - 8s 166ms/step - loss: 0.0304 - accuracy_within_05cm: 1.0000 - accuracy_within_1cm: 1.0000 - mean_error_cm: 1.2814e-04 - mean_io_u_7: 0.4962\n",
      "Validation loss: [0.030431285500526428, 1.0, 1.0, 0.00012814364163205028, 0.4962385296821594]\n",
      "47/47 [==============================] - 9s 171ms/step - loss: 0.0324 - accuracy_within_05cm: 1.0000 - accuracy_within_1cm: 1.0000 - mean_error_cm: 1.4141e-04 - mean_io_u_8: 0.4963\n",
      "Validation loss: [0.03243715316057205, 1.0, 1.0, 0.0001414094731444493, 0.4962545335292816]\n",
      "48/48 [==============================] - 9s 174ms/step - loss: 0.0234 - accuracy_within_05cm: 1.0000 - accuracy_within_1cm: 1.0000 - mean_error_cm: 9.5267e-05 - mean_io_u_9: 0.4962\n",
      "Validation loss: [0.023368695750832558, 1.0, 1.0, 9.526664507575333e-05, 0.49621468782424927]\n",
      "48/48 [==============================] - 9s 166ms/step - loss: 0.0221 - accuracy_within_05cm: 1.0000 - accuracy_within_1cm: 1.0000 - mean_error_cm: 1.0170e-04 - mean_io_u_10: 0.4963\n",
      "Validation loss: [0.02208402194082737, 1.0, 1.0, 0.000101700599770993, 0.49628832936286926]\n"
     ]
    }
   ],
   "source": [
    "# 評估測試集\n",
    "for fold in range(1,6):\n",
    "    testGene = test_aug_generator(fold)\n",
    "    model = UNetPlusPlus()\n",
    "    model.load_weights(f\"best_model/{modeltype}/Fold{fold}.keras\")\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[accuracy_within_05cm, accuracy_within_1cm,mean_error_cm,MeanIoU(num_classes=2)])\n",
    "    steps = count_files(f\"ETT_predict/{modeltype}/Fold{fold}\")\n",
    "    loss = model.evaluate(valGene, steps=steps)\n",
    "    print('Validation loss:', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 1s 12ms/step\n",
      "47/47 [==============================] - 1s 12ms/step\n",
      "47/47 [==============================] - 1s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/UNetPlusPlus/Fold3\\1_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/UNetPlusPlus/Fold3\\32_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 1s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/UNetPlusPlus/Fold4\\0_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/UNetPlusPlus/Fold4\\5_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/UNetPlusPlus/Fold4\\9_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/UNetPlusPlus/Fold4\\27_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/UNetPlusPlus/Fold4\\39_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/UNetPlusPlus/Fold4\\41_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 1s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/UNetPlusPlus/Fold5\\11_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/UNetPlusPlus/Fold5\\23_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/UNetPlusPlus/Fold5\\33_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n"
     ]
    }
   ],
   "source": [
    "# 預測 mask\n",
    "for fold in range(1,6):\n",
    "    testGene = test_aug_generator(fold)\n",
    "    model = UNetPlusPlus()\n",
    "    model.load_weights(f\"best_model/{modeltype}/Fold{fold}.keras\")\n",
    "    results = model.predict(testGene,verbose=1)\n",
    "    saveResult(f\"ETT_predict/{modeltype}/Fold{fold}\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in range(1,6):\n",
    "    testGene = test_aug_generator(fold)\n",
    "    model = UNetPlusPlus()\n",
    "    model.load_weights(f\"best_model/{modeltype}/Fold{fold}.keras\")\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[accuracy_within_05cm, accuracy_within_1cm,mean_error_cm,MeanIoU(num_classes=2)])\n",
    "    loss = model.evaluate(valGene, steps=64)\n",
    "    print('Validation loss:', loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
