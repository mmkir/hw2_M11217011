{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from package.model import *\n",
    "from package.function import *\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltype = 'FCN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_args = dict(rotation_range=0.2,\n",
    "                     width_shift_range=0.05,\n",
    "                     height_shift_range=0.05,\n",
    "                     shear_range=0.05,\n",
    "                     zoom_range=0.05,\n",
    "                     horizontal_flip=True,\n",
    "                     fill_mode='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 47 images belonging to 1 classes.\n",
      "Found 47 images belonging to 1 classes.\n",
      "64/64 [==============================] - 28s 434ms/step - loss: 0.0144 - accuracy_within_05cm: 1.0000 - accuracy_within_1cm: 1.0000 - mean_error_cm: 8.0968e-05 - mean_io_u_6: 0.4959\n",
      "Validation loss: [0.014375176280736923, 1.0, 1.0, 8.096815145108849e-05, 0.49589741230010986]\n",
      "Found 47 images belonging to 1 classes.\n",
      "Found 47 images belonging to 1 classes.\n",
      "64/64 [==============================] - 30s 460ms/step - loss: 0.0197 - accuracy_within_05cm: 1.0000 - accuracy_within_1cm: 1.0000 - mean_error_cm: 1.2472e-04 - mean_io_u_7: 0.4963\n",
      "Validation loss: [0.019691068679094315, 1.0, 1.0, 0.0001247172331204638, 0.4963069558143616]\n",
      "Found 47 images belonging to 1 classes.\n",
      "Found 47 images belonging to 1 classes.\n",
      "64/64 [==============================] - 29s 453ms/step - loss: 0.0237 - accuracy_within_05cm: 1.0000 - accuracy_within_1cm: 1.0000 - mean_error_cm: 1.2027e-04 - mean_io_u_8: 0.4959\n",
      "Validation loss: [0.023718342185020447, 1.0, 1.0, 0.00012026867625536397, 0.4958794116973877]\n",
      "Found 48 images belonging to 1 classes.\n",
      "Found 48 images belonging to 1 classes.\n",
      "64/64 [==============================] - 31s 474ms/step - loss: 0.0130 - accuracy_within_05cm: 1.0000 - accuracy_within_1cm: 1.0000 - mean_error_cm: 1.1157e-04 - mean_io_u_9: 0.4960\n",
      "Validation loss: [0.012977293692529202, 1.0, 1.0, 0.00011156866094097495, 0.4959726631641388]\n",
      "Found 48 images belonging to 1 classes.\n",
      "Found 48 images belonging to 1 classes.\n",
      "64/64 [==============================] - 29s 443ms/step - loss: 0.0150 - accuracy_within_05cm: 1.0000 - accuracy_within_1cm: 1.0000 - mean_error_cm: 1.0367e-04 - mean_io_u_10: 0.4962\n",
      "Validation loss: [0.01501371804624796, 1.0, 1.0, 0.0001036655594361946, 0.496232271194458]\n"
     ]
    }
   ],
   "source": [
    "# 評估驗證集\n",
    "for fold in range(1,6):\n",
    "    # Validation data generator\n",
    "    valGene = trainGenerator(batch_size=10,\n",
    "                            train_path=f'ETT_v3/Fold{fold}',\n",
    "                            image_folder='val',\n",
    "                            mask_folder='valannot',\n",
    "                            aug_dict=data_gen_args,\n",
    "                            save_to_dir=None)\n",
    "    model = fcn()\n",
    "    model.load_weights(f\"best_model/{modeltype}/Fold{fold}.keras\")\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[accuracy_within_05cm, accuracy_within_1cm,mean_error_cm,MeanIoU(num_classes=2)])\n",
    "    loss = model.evaluate(valGene, steps=64)\n",
    "    print('Validation loss:', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 27s 570ms/step - loss: 0.0102 - accuracy_within_05cm: 1.0000 - accuracy_within_1cm: 1.0000 - mean_error_cm: 6.8659e-05 - mean_io_u_12: 0.4963\n",
      "Validation loss: [0.010155987925827503, 1.0, 1.0, 6.865857722004876e-05, 0.4962567985057831]\n",
      "47/47 [==============================] - 25s 500ms/step - loss: 0.0140 - accuracy_within_05cm: 1.0000 - accuracy_within_1cm: 1.0000 - mean_error_cm: 9.8285e-05 - mean_io_u_13: 0.4962\n",
      "Validation loss: [0.013994400389492512, 1.0, 1.0, 9.82849596766755e-05, 0.49621954560279846]\n",
      "47/47 [==============================] - 26s 535ms/step - loss: 0.0157 - accuracy_within_05cm: 1.0000 - accuracy_within_1cm: 1.0000 - mean_error_cm: 1.0134e-04 - mean_io_u_14: 0.4963\n",
      "Validation loss: [0.01565088890492916, 1.0, 1.0, 0.00010133780597243458, 0.49625930190086365]\n",
      "48/48 [==============================] - 24s 497ms/step - loss: 0.0110 - accuracy_within_05cm: 1.0000 - accuracy_within_1cm: 1.0000 - mean_error_cm: 1.0309e-04 - mean_io_u_15: 0.4963\n",
      "Validation loss: [0.010956894606351852, 1.0, 1.0, 0.00010308805940439925, 0.4962567090988159]\n",
      "48/48 [==============================] - 26s 537ms/step - loss: 0.0150 - accuracy_within_05cm: 1.0000 - accuracy_within_1cm: 1.0000 - mean_error_cm: 1.0455e-04 - mean_io_u_16: 0.4962\n",
      "Validation loss: [0.014999058097600937, 1.0, 1.0, 0.00010454867879161611, 0.4962221086025238]\n"
     ]
    }
   ],
   "source": [
    "# 評估測試集\n",
    "for fold in range(1,6):\n",
    "    testGene = test_aug_generator(fold)\n",
    "    model = fcn()\n",
    "    model.load_weights(f\"best_model/{modeltype}/Fold{fold}.keras\")\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[accuracy_within_05cm, accuracy_within_1cm,mean_error_cm,MeanIoU(num_classes=2)])\n",
    "    steps = count_files(f\"ETT_predict/{modeltype}/Fold{fold}\")\n",
    "    loss = model.evaluate(valGene, steps=steps)\n",
    "    print('Validation loss:', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 3s 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold1\\7_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold1\\11_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold1\\13_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold1\\14_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold1\\16_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold1\\18_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold1\\20_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold1\\29_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold1\\38_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold1\\44_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 2s 37ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold2\\1_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold2\\11_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold2\\24_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold2\\30_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold2\\34_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold2\\42_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 2s 37ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold3\\0_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold3\\1_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold3\\6_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold3\\9_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold3\\16_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold3\\18_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold3\\19_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold3\\22_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold3\\33_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold3\\42_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 2s 38ms/step\n",
      "48/48 [==============================] - 2s 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold5\\5_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold5\\22_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold5\\23_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold5\\33_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold5\\35_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold5\\38_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold5\\41_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n",
      "d:\\學業\\碩士課程\\機器瘸習\\分組作業\\專題二\\正式版\\package\\function.py:142: UserWarning: ETT_predict/FCN/Fold5\\42_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path, f\"{i}_predict.png\"), img)\n"
     ]
    }
   ],
   "source": [
    "# 預測 mask\n",
    "for fold in range(1,6):\n",
    "    testGene = test_aug_generator(fold)\n",
    "    model = fcn()\n",
    "    model.load_weights(f\"best_model/{modeltype}/Fold{fold}.keras\")\n",
    "    results = model.predict(testGene,verbose=1)\n",
    "    saveResult(f\"ETT_predict/{modeltype}/Fold{fold}\",results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
